# =========================================================================== #
#           FILE:  sysctl-boilerplate.conf                                    #
#          USAGE:  edit parameters and put them into /etc/sysctl.conf         #
#                                                                             #
#    DESCRIPTION:  This is a boilerplate of /etc/sysctl.conf kernel config    #
#                  adopted for server use with any modern Linux distribution. #
#                  This file contains some basic tweaks for different kernel  #
#                  parameters which can increase performance, responsiveness  #
#                  and network throughput in the high-load scenario for web   #
#                  server, streaming or storage server, e.t.c.                #
#                                                                             #
#   REQUIREMENTS:  /dev/brain, /dev/hands                                     #
#          NOTES:  YOU MUST ADJUST ALL THESE PARAMETERS FOR YOUR SITUATION!   #
#                  Also do not change the value of any kernel parameter on a  #
#                  system where it is already set higher than listed as       #
#                  minimum requirement in this boilerplate.                   #
#         AUTHOR:  Stanislav "systematicat" Kotivetc, <@systematicat>         #
#        COMPANY:  Hire me! I am a cool dude!                                 #
#        VERSION:  1.0                                                        #
#        CREATED:  09.01.2017 - 17:15                                         #
#      COPYRIGHT:  2017 Stanislav "systematicat" Kotivetc                     #
#        LICENSE:  WTFPL v2                                                   #
# =========================================================================== #

###############################################################################
########################## GENERAL SYSTEM OPTIONS #############################
###############################################################################

# Controls the System Request debugging functionality of the kernel.
# In most of the situations you do not need Magic SysRq.
kernel.sysrq = 0

# Controls whether core dumps will append the PID to the core filename.
# Useful when you for example debugging multi-threaded applications.
kernel.core_uses_pid = 1

# Set amount of PIDs that can run simultaneously in separate memory spaces.
kernel.pid_max = 65535

# Set content of /proc/<pid>/maps and smaps files are only visible to
# readers that are allowed to ptrace() the process. Usually it is useless.
# kernel.maps_protect = 1

# Enable ExecShield protection. Usually doesn't work in Ubuntu because it uses
# hardware NX when the CPU supports it or uses NX emulation in the kernel
# equivalent of the Red Hat Exec Shield patch.
# kernel.exec-shield = 1

# Enable random placement of virtual memory regions protection.
# Address Space Layout Randomization can help defeat certain types of buffer
# overflow attacks. Setting parameter 2 will randomize the positions of
# the stack, VDSO page, shared memory regions, and the data segment.
kernel.randomize_va_space = 2

# Controls the default max size of queue and default max size of message.
# I use these values from IBM DB2 user manual most of the time.
kernel.msgmnb = 65535
kernel.msgmax = 65535

# Set the system wide maximum number of shared memory segments.
# value = 256*<total_memory_in_GB>. But Oracle and IBM recommends 4096.
kernel.shmmni = 4096

# Define the maximum size in bytes of a single shared memory segment that a
# Linux process can allocate in its virtual address space.
# value = <total_memory_in_bytes>.
kernel.shmmax = 17179869184

# Sets the total amount of shared memory pages that can be used system wide.
# Hence, SHMALL should always be at least 2*<shmmax>/<PAGE_SIZE>.
# To find the default PAGE_SIZE run command $getconf PAGE_SIZE.
kernel.shmall = 8388608

# Setting Semaphores.
# <SEMMSL> = Oracle recommends at least 250.
# <SEMMNS> = <SEMMSL>*<SEMMNI> Oracle recommends SEMMSL to be at least 32000.
# <SEMOPM> = Oracle recommends to set SEMOPM to a minimum value of 100
# <SEMMNI> = <total_memory_in_GB>*256 but Oracle set SEMMNI at least 128.
# Syntax is kernel.sem = <SEMMSL> <SEMMNS> <SEMOPM> <SEMMNI>
kernel.sem = 250 1024000 100 4096

# Set number of message queue identifiers.
# value = 1024*<total_memory_in_GB>.
kernel.msgmni = 16384

# This toggle indicates whether restrictions are placed on exposing kernel
# addresses via /proc and other interfaces.
kernel.kptr_restrict = 1

# 0 - (default) - traditional behaviour. Any process which has changed
# privilege levels or is execute only will not be dumped.
# 1 - (debug only) - all processes dump core when possible. The core dump is
# owned by the current user and no security is applied.
# 2 - (suidsafe) - any binary which normally not be dumped is dumped readable
# by root only. End user can remove such a dump but not access it directly.
fs.suid_dumpable = 0

# Increase size of file handles and inode cache.
# value = <_PHYS_PAGES>*<PAGE_SIZE>/1024/10.
# Find values = $getconf _PHYS_PAGES and $getconf PAGE_SIZE.
fs.file-max = 785928

###############################################################################
######################### MEMORY SUBSYSTEM OPTIONS ############################
###############################################################################

# If we have lots of memory we will avoid of using swap.
# We want swappiness to be as close to zero as possible.
vm.swappiness = 0

# Tell Linux that we want it to prefer inode/dentry cache to other caches.
# Higher priority to inode caching helps to avoid disk seeks for inode loading.
vm.vfs_cache_pressure = 50

# To avoid long IO stalls for write cache in a real life situation with
# different workloads we typically want to limit the kernel dirty cache size.
# Rule of thumb: <dirty_background_ratio> = 1/4 to 1/2 of the <dirty_ratio>.
vm.dirty_background_ratio = 5
vm.dirty_ratio = 10

# Set the 50% of available memory overcommit policy.
vm.overcommit_ratio = 50
vm.overcommit_memory = 0

# But if you run out of memory use next settings that don't do overcommit and
# the total address space will be <swap>+<ram>*<overcommit_ratio>/100.
# vm.overcommit_ratio = 100
# vm.overcommit_memory = 2
# And more. If you run Docker or Redis and have some memory troubles try this:
# vm.overcommit_memory = 1
# vm.overcommit_ratio = 50

# Specifies the minimum virtual address that a process is allowed to mmap.
# It avoids "kernel NULL pointer dereference" defects.
vm.mmap_min_addr = 4096

# Keep at least 128MB of free RAM space available. When set to its default
# value it is possible to encounter memory exhaustion symptoms when free memory
# should in fact be available. Setting <vm.min_free_kbytes> to 5-6% of the
# total physical memory but no more than 2GB can prevent this problem.
vm.min_free_kbytes = 131072

# RED HAT DOES NOT RECOMMEND TUNNING THIS PARAMETER!
# Specifies the number of centiseconds (hundredths of a second) dirty data
# remains in the page cache before it is eligible to be written back to disk.
# vm.dirty_expire_centisecs = 6000

# RED HAT DOES NOT RECOMMEND TUNNING THIS PARAMETER!
# Specifies the length of the interval between kernel flusher threads waking
# and writing eligible data to disk.
# vm.dirty_writeback_centisecs = 6000

###############################################################################
########################## NETWORK SPEED TWEAKS ###############################
###############################################################################

# Turn on the tcp_timestamps. More accurate timestamp make TCP congestion
# control algorithms work better and are recommended for fast networks.
net.ipv4.tcp_timestamps = 1

# Increase number of incoming connections backlog. Try up to 262144.
net.core.netdev_max_backlog = 16384

# Set max number half open SYN requests to keep in memory.
net.ipv4.tcp_max_syn_backlog = 8192

# Do not cache ssthresh from previous connection.
net.ipv4.tcp_no_metrics_save = 1
net.ipv4.tcp_moderate_rcvbuf = 1

# Explicitly set htcp or cubic as the congestion control. To get a list of
# congestion control algorithms that are available in your kernel run:
# command $sysctl net.ipv4.tcp_available_congestion_control and to find algo
# that can be loaded run $grep TCP_CONG /boot/config-$(uname -r).
# also read this - http://fasterdata.es.net/host-tuning/linux/
#net.ipv4.tcp_congestion_control = cubic

# For servers with tcp-heavy workloads, enable <fq> queue management scheduler.
# Highly recommended for CentOS7/Debian8 hosts.
#net.core.default_qdisc = fq

# If you are using Jumbo Frames, also set this tunable.
# net.ipv4.tcp_mtu_probing = 1

# Set max number of queued connections on a socket. The default value usually
# is too low. Raise this value substantially to support bursts of request.
#Modified
net.core.somaxconn = 98192

# Try to reuse time-wait connections.
# But don't recycle them (recycle can break clients behind NAT).
net.ipv4.tcp_tw_recycle = 0
net.ipv4.tcp_tw_reuse = 1

# Avoid falling back to slow start after a connection goes idle.
# Keep it 0 usually.
net.ipv4.tcp_slow_start_after_idle = 0

# Enable TCP window scaling for high-throughput blazing fast TCP performance.
net.ipv4.tcp_window_scaling = 1

# Decrease the time default value for tcp_fin_timeout connection.
net.ipv4.tcp_fin_timeout = 10

# Decrease the time default value for connections to keep alive.
#net.ipv4.tcp_keepalive_time = 512
#net.ipv4.tcp_keepalive_probes = 10
#net.ipv4.tcp_keepalive_intvl = 32

# Limit orphans because each orphan can eat up to 16M of unswappable memory.
#net.ipv4.tcp_max_orphans = 16384
#net.ipv4.tcp_orphan_retries = 0

# Increase the maximum memory used to reassemble IP fragments.
net.ipv4.ipfrag_high_thresh = 589824
net.ipv4.ipfrag_low_thresh = 524288

# Increase size of RPC datagram queue length.
net.unix.max_dgram_qlen = 512

# Do not allow the arp table to become bigger than this
net.ipv4.neigh.default.gc_thresh3 = 40960

# Tell the gc when to become aggressive with arp table cleaning.
net.ipv4.neigh.default.gc_thresh2 = 20480

# Adjust where the gc will leave arp table alone.
net.ipv4.neigh.default.gc_thresh1 = 1024

# Adjust to arp table gc to clean-up more often
net.ipv4.neigh.default.gc_interval = 300

# Increase TCP queue length in order to reduce a performance spike with
# relation to timestamps generation.
net.ipv4.neigh.default.proxy_qlen = 9600
net.ipv4.neigh.default.unres_qlen = 600

# Enable a fix for RFC1337 - time-wait assassination hazards in TCP.
net.ipv4.tcp_rfc1337 = 1

# This will ensure that immediately subsequent connections use the new values.
net.ipv4.route.flush = 1
net.ipv6.route.flush = 1

# Set 1 if you want to disable Path MTU discovery - a technique to determine
# the largest Maximum Transfer Unit possible on your path.
net.ipv4.ip_no_pmtu_disc = 0

# Use Selective ACK which can be used to signify that specific packets are
# missing - therefore helping fast recovery.
net.ipv4.tcp_sack = 1

# Enables Forward Acknowledgment which works with Selective Acknowledgment.
# Intel recommends to turn in always on.
net.ipv4.tcp_fack = 1

# ECN allows end-to-end notification of network congestion without dropping
# packets. It is nice as concept in RFC but in the real life we have a lot of
# crapy network hardware so disable it.
net.ipv4.tcp_ecn = 0

# Enable(0)/disable(1) the PreQueue entirely. Allow tcp/ip stack prefer
# low latency instead of high throughput. Try option 1 in slow Wi-Fi networks.
# IBM recommend set it to 0.
net.ipv4.tcp_low_latency = 0

# Enables Forward RTO-Recovery (F-RTO) defined in RFC4138. F-RTO is an enhanced
# recovery algorithm for TCP retransmission timeouts. It is usually good to use
# in wireless environments where packet loss is typically due to random radio
# interference rather than intermediate router congestion. Option 1 - basic
# version is enabled. Option 2 enables SACK enhanced F-RTO if flow uses SACK.
# Default is 2 but changing it to 1 sometimes improves the performance.
net.ipv4.tcp_frto = 2

# 0 - Rate halving based; a smooth and conservative response, results in halved
# cwnd and ssthresh after one RTT. 1 - Very conservative response; not
# recommended because even though being valid, it interacts poorly with the
# rest of Linux TCP, halves cwnd and ssthresh immediately.
# 2 - Aggressive response; undoes congestion control measures that are now
# known to be unnecessary (ignoring the possibility of a lost retransmission
# that would require TCP to be more cautious), cwnd and ssthresh are restored
# to the values prior timeout. Default is 0.
# Also on some distribution this tunable is deprecated.
net.ipv4.tcp_frto_response = 2

# Enable TCP Fast Open (RFC7413) to send and accept data in the opening
# SYN-packet. It will not do any troubles with not supported hosts
# but it will do guaranteed speedup handshake for supported ones.
net.ipv4.tcp_fastopen = 1

# Set UDP parameters. Adjust them for your network.
net.ipv4.udp_mem = 8388608 12582912 16777216
net.ipv4.udp_rmem_min = 65536
net.ipv4.udp_wmem_min = 65536

# Increase Linux auto-tuning TCP buffer limits.
# Set max to 16MB buffer (16777216) for 1GE network.
#net.core.rmem_max = 167772160
#net.core.wmem_max = 167772160
#net.core.rmem_default = 167772160
#net.core.wmem_default = 167772160
#net.core.optmem_max = 40960
#net.ipv4.tcp_rmem = 40960 873800 167772160
#net.ipv4.tcp_wmem = 40960 655360 167772160

# Setting 10GE capable host to consume a maximum of 32M-64M per socket ensures
# parallel streams work well and do not consume a majority of system resources.
# Set max 32MB buffer (33554432) for 10GE network.
net.core.rmem_max = 33554432
net.core.wmem_max = 33554432
net.core.rmem_default = 33554432
net.core.wmem_default = 33554432
net.core.optmem_max = 40960
net.ipv4.tcp_rmem = 4096 87380 33554432
net.ipv4.tcp_wmem = 4096 65536 33554432

#For a host with a 10G NIC optimized for network paths up to 200ms RTT, 
#and for friendliness to single and parallel stream tools, or a 40G NIC up on paths up to 50ms RTT:
#http://fasterdata.es.net/host-tuning/linux/

# allow testing with buffers up to 128MB
#net.core.rmem_max = 134217728 
#net.core.wmem_max = 134217728 
# increase Linux autotuning TCP buffer limit to 64MB
#net.ipv4.tcp_rmem = 4096 87380 67108864
#net.ipv4.tcp_wmem = 4096 65536 67108864
# recommended default congestion control is htcp 
#net.ipv4.tcp_congestion_control=htcp
# recommended for hosts with jumbo frames enabled
#net.ipv4.tcp_mtu_probing=1
# recommended for CentOS7+/Debian8+ hosts
net.core.default_qdisc = fq
